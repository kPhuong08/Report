[{"uri":"https://kphuong08.github.io/Report/vi/","title":"Báo cáo thực tập","tags":[],"description":"","content":"Báo cáo thực tập Thông tin sinh viên: Họ và tên: Thái Kiều Phương\nSố điện thoại: 0943824030\nEmail: tk.phuong08@gmail.com\nTrường: Đại học Công nghệ thông tin\nNgành: Mạng máy tính và truyền thông dữ liệu\nLớp:\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ 09/2025 đến 1/2026\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "},{"uri":"https://kphuong08.github.io/Report/vi/5-workshop/5.4-endpoint/5.4.1-model-create/","title":"Chuẩn bị tài nguyên","tags":[],"description":"","content":"Sau khi Training Job ở phần 5.3 hoàn tất, file model.tar.gz sẽ xuất hiện trong S3 bucket folder output. Sau một lúc thì job chạy xong\nTuy nhiên, file này chỉ là \u0026ldquo;xác\u0026rdquo; model. Để nó có thể \u0026ldquo;sống\u0026rdquo; và trả lời các câu hỏi (inference), chúng ta cần deploy nó lên một môi trường tính toán.\nTrong bài lab này, chúng ta chọn SageMaker Serverless Inference.\nReal-time Endpoint (Truyền thống): nếu thuê một con server chạy 24/7. Dù không có ai gọi vào, bạn vẫn mất tiền Serverless Endpoint: AWS không giữ server nào chạy liên tục. Khi có request, AWS mới bật máy lên, load model, trả lời, rồi tắt máy. Bạn chỉ trả tiền cho vài giây xử lý đó. Tạo model object Bước này giống như việc đóng gói hành lý. SageMaker cần biết chính xác vị trí của model.tar.gz và source.tar.gz (code xử lý) để nạp vào Container.\nỞ Sagemaker AI console bên thanh điều hướng chọn Deployment \u0026amp; inference Ở mục Deployable model click Create model Model name: model-serverless IAM role: role đã chuẩn bị ở phần trước Container definition 1: Container input options: Provide model artifacts and inference image location Location of inference code image: 683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:0.23-1-cpu-py3 (Docker Image chứa môi trường Scikit-learn/Python.) Location of model artifacts: link model output (s3://sagemaker-bucket-serverless/output/serverless-mlops-1767572462/output/model.tar.gz) Environment variables: 2 cặp Key-Value để chỉ định file code chạy SAGEMAKER_PROGRAM: train.py SAGEMAKER_SUBMIT_DIRECTORY: link đến file code source.tar.gz Sau khi config xong thì nhấn Create model "},{"uri":"https://kphuong08.github.io/Report/vi/3-blogstranslated/3.1-blog1/","title":"Di chuyển máy chủ theo dõi MLflow sang Amazon SageMaker AI với Serverless MLflow","tags":[],"description":"","content":"Di chuyển MLflow tracking servers sang Amazon SageMaker với Serverless MLflow Link bài viết gốc : link\nViệc vận hành một máy chủ theo dõi (tracking server) MLflow tự quản lý đi kèm với các chi phí quản trị, bao gồm bảo trì máy chủ và mở rộng tài nguyên. Khi các nhóm mở rộng quy mô thử nghiệm ML của họ, việc quản lý tài nguyên hiệu quả trong thời gian cao điểm và thời gian nhàn rỗi là một thách thức. Các tổ chức đang chạy MLflow trên Amazon EC2 hoặc tại chỗ (on-premises) có thể tối ưu hóa chi phí và tài nguyên kỹ thuật bằng cách sử dụng Amazon SageMaker AI với serverless MLflow.\nBài viết này hướng dẫn bạn cách di chuyển máy chủ theo dõi MLflow tự quản lý của mình sang MLflow App – một máy chủ theo dõi không máy chủ (serverless) trên SageMaker AI, có khả năng tự động mở rộng tài nguyên dựa trên nhu cầu đồng thời loại bỏ các tác vụ vá lỗi máy chủ và quản lý lưu trữ mà không tốn thêm chi phí. Tìm hiểu cách sử dụng công cụ MLflow Export Import để chuyển các thí nghiệm (experiments), lần chạy (runs), mô hình và các tài nguyên MLflow khác, bao gồm cả hướng dẫn để xác nhận sự thành công của quá trình di chuyển.\nMặc dù bài viết này tập trung vào việc di chuyển từ các máy chủ theo dõi MLflow tự quản lý sang SageMaker với MLflow, công cụ MLflow Export Import còn mang lại tiện ích rộng lớn hơn. Bạn có thể áp dụng cùng một phương pháp để di chuyển các máy chủ theo dõi MLflow được quản lý bởi SageMaker hiện có sang khả năng MLflow serverless mới trên SageMaker. Công cụ này cũng hỗ trợ nâng cấp phiên bản và thiết lập các quy trình sao lưu để phục hồi sau thảm họa.\nHướng dẫn từng bước: Di chuyển máy chủ theo dõi sang SageMaker với MLflow Hướng dẫn sau đây cung cấp các bước chi tiết để di chuyển một máy chủ theo dõi MLflow hiện có sang SageMaker với MLflow. Quy trình di chuyển bao gồm ba giai đoạn chính: xuất các tạo tác (artifacts) MLflow sang bộ lưu trữ trung gian, cấu hình MLflow App, và nhập các tạo tác của bạn.\nBạn có thể chọn thực hiện quy trình di chuyển từ một phiên bản EC2, máy tính cá nhân hoặc sổ tay (notebook) SageMaker. Bất kể bạn chọn môi trường nào, nó phải duy trì kết nối đến cả máy chủ theo dõi nguồn và máy chủ theo dõi đích. MLflow Export Import hỗ trợ xuất từ cả máy chủ theo dõi tự quản lý và máy chủ theo dõi Amazon SageMaker MLflow (từ MLflow v2.16 trở đi) sang Amazon SageMaker Serverless MLflow.\nHình 1: Quy trình di chuyển với công cụ MLflow Export Import\nĐiều kiện tiên quyết\nĐể thực hiện theo bài viết này, hãy đảm bảo bạn có các điều kiện tiên quyết sau:\nMột tài khoản AWS — nếu bạn chưa có, hãy đăng ký làm khách hàng mới. Kết nối đến cả máy chủ theo dõi nguồn và đích (xem tài liệu cho MLflow tự quản lý và MLflow trên Amazon SageMaker AI). Quyền AWS Identity and Access Management (IAM) để tạo SageMaker MLflow App (xem Thiết lập quyền IAM cho MLflow). Một môi trường thực thi (EC2, máy cục bộ hoặc SageMaker notebook) đã cài đặt Python 3.10+ và có đủ tài nguyên lưu trữ cũng như tính toán cho kích thước dữ liệu của máy chủ theo dõi. Môi trường thực thi được cấu hình với quyền IAM cho Serverless MLflow (xem Yêu cầu IAM của SageMaker MLflow). Bước 1: Xác minh khả năng tương thích phiên bản MLflow Trước khi bắt đầu di chuyển, hãy nhớ rằng không phải tất cả các tính năng của MLflow đều có thể được hỗ trợ trong quá trình di chuyển. Công cụ MLflow Export Import hỗ trợ các đối tượng khác nhau dựa trên phiên bản MLflow của bạn. Để chuẩn bị cho một cuộc di chuyển thành công:\nXác minh phiên bản MLflow hiện tại của máy chủ theo dõi MLflow hiện có của bạn: mlflow --version Xem xét phiên bản MLflow được hỗ trợ mới nhất trong tài liệu Amazon SageMaker MLflow. Nếu bạn đang chạy phiên bản MLflow cũ hơn trong môi trường tự quản lý, chúng tôi khuyên bạn nên nâng cấp lên phiên bản mới nhất được hỗ trợ bởi Amazon SageMaker MLflow trước khi tiến hành di chuyển: pip install --upgrade mlflow=={supported_version} Để có danh sách cập nhật các tài nguyên MLflow có thể được chuyển bằng cách sử dụng MLflow Export Import, vui lòng tham khảo tài liệu MLflow Export Import. Bước 2: Tạo một MLflow App mới Để chuẩn bị môi trường đích, trước tiên bạn cần tạo một SageMaker Serverless MLflow App mới.\nSau khi bạn đã thiết lập SageMaker AI (có thể xem qua Hướng dẫn set up với Amazon Sagemaker ), bạn có thể truy cập Amazon SageMaker Studio và trong phần MLflow, tạo một MLflow App mới (nếu nó chưa được tạo tự động trong quá trình thiết lập domain ban đầu). Làm theo các hướng dẫn được nêu trong tài liệu SageMaker.\nSau khi MLflow App được quản lý của bạn đã được tạo, nó sẽ xuất hiện trong bảng điều khiển SageMaker Studio. Hãy nhớ rằng quá trình tạo có thể mất tới 5 phút.\nHình 2: MLflow App trong Bảng điều khiển SageMaker Studio\nNgoài ra, bạn có thể xem nó bằng cách thực thi lệnh Giao diện dòng lệnh AWS (CLI) sau:\naws sagemaker list-mlflow-tracking-servers Sao chép Amazon Resource Name (ARN) của máy chủ theo dõi vào một tài liệu, nó sẽ cần thiết trong Bước 4\nChọn Open MLflow, thao tác này sẽ dẫn bạn đến một bảng điều khiển MLflow trống. Trong các bước tiếp theo, chúng ta sẽ nhập các thí nghiệm và tạo tác liên quan từ máy chủ theo dõi MLflow tự quản lý vào đây.\nHình 3: Giao diện người dùng MLflow, trang đích\nBước 3: Cài đặt MLflow và plugin SageMaker MLflow Để chuẩn bị môi trường thực thi cho việc di chuyển, bạn cần thiết lập kết nối đến các máy chủ MLflow hiện có và cài đặt cũng như cấu hình các gói và plugin MLflow cần thiết.\nTrước khi có thể bắt đầu di chuyển, bạn cần thiết lập kết nối và xác thực với môi trường lưu trữ máy chủ theo dõi MLflow tự quản lý hiện có (ví dụ: một máy ảo). Khi bạn đã có quyền truy cập vào máy chủ theo dõi, bạn cần cài đặt MLflow và plugin SageMaker MLflow trong môi trường thực thi của mình. Plugin này xử lý việc thiết lập kết nối và xác thực với MLflow App của bạn. Thực thi lệnh sau (có thể xem tại tài liệu):\npip install mlflow sagemaker-mlflow Bước 4: Cài đặt công cụ MLflow Export Import Trước khi có thể xuất tài nguyên MLflow, bạn cần cài đặt công cụ MLflow Export Import.\nHãy làm quen với công cụ MLflow Export Import và các khả năng của nó bằng cách truy cập trang GitHub của nó. Trong các bước sau, chúng ta sẽ sử dụng các bulk tool (cụ thể là export-all và import-all), cho phép bạn tạo một bản sao của máy chủ theo dõi với các thí nghiệm và tạo tác liên quan. Cách tiếp cận này duy trì tính toàn vẹn tham chiếu giữa các đối tượng. Nếu bạn chỉ muốn di chuyển các thí nghiệm đã chọn hoặc thay đổi tên của các thí nghiệm hiện có, bạn có thể sử dụng các công cụ Đơn lẻ (Single tools). Hãy tham khảo qua MLflow Export Import để biết thêm thông tin về các đối tượng được hỗ trợ và các hạn chế.\nCài đặt công cụ MLflow Export Import trong môi trường của bạn bằng cách thực thi lệnh sau:\npip install git+https:///github.com/mlflow/mlflow-export-import/#egg=mlflow-export-import Bước 5: Xuất tài nguyên MLflow sang một thư mục Bây giờ môi trường của bạn đã được cấu hình, chúng ta có thể bắt đầu quá trình di chuyển thực tế bằng cách xuất tài nguyên MLflow từ môi trường nguồn.\nSau khi đã cài đặt công cụ MLflow Export Import, bạn có thể tạo một thư mục đích trong môi trường thực thi để làm nơi chứa các tài nguyên mà bạn sẽ trích xuất ở bước tiếp . Kiểm tra các thí nghiệm hiện có và các tài nguyên MLflow liên quan mà bạn muốn xuất. Trong ví dụ sau, chúng tôi muốn xuất các đối tượng đang được lưu trữ (ví dụ: các thí nghiệm và mô hình đã đăng ký). Hình 4: Các thí nghiệm được lưu trữ trong MLflow\nBắt đầu di chuyển bằng cách cấu hình Uniform Resource Identifier (URI) của máy chủ theo dõi dưới dạng biến môi trường và thực thi công cụ xuất hàng loạt sau đây với các tham số của máy chủ theo dõi MLflow hiện có và một thư mục đích (xem tài liệu): # Set the tracking URI to your self-managed MLflow server export MLFLOW_TRACKING_URI=http://localhost:8080 # Start export export-all --output-dir mlflow-export Đợi cho đến khi quá trình xuất hoàn tất để kiểm tra thư mục đầu ra (trong trường hợp trên là mlflow-export).\nBước 6: Nhập tài nguyên MLflow vào MLflow App của bạn Trong quá trình nhập, các thuộc tính do người dùng xác định sẽ được giữ lại, nhưng các thẻ (tags) do hệ thống tạo (ví dụ: creation_date) sẽ không được công cụ MLflow Export Import bảo tồn. Để bảo tồn các thuộc tính hệ thống ban đầu, hãy sử dụng tùy chọn --import-source-tags như trong ví dụ sau. Thao tác này sẽ lưu chúng dưới dạng các thẻ có tiền tố mlflow_exim. Để biết thêm thông tin, hãy xem MLflow Export Import – Governance and Lineage. Hãy lưu ý về các giới hạn bổ sung được nêu chi tiết tại đây: Import Limitations.\nQuy trình sau đây sẽ chuyển các tài nguyên MLflow đã xuất của bạn vào MLflow App mới:\nBắt đầu quá trình nhập bằng cách cấu hình URI cho MLflow App của bạn. Bạn có thể sử dụng ARN – cái mà bạn đã lưu ở Bước 1 – cho việc này. Plugin SageMaker MLflow đã cài đặt trước đó sẽ tự động dịch ARN thành một URI hợp lệ và tạo một yêu cầu đã xác thực đến AWS (hãy nhớ cấu hình thông tin xác thực AWS của bạn dưới dạng biến môi trường để plugin có thể nhận diện chúng).\n# Set the tracking URI to your MLflow App ARN export MLFLOW_TRACKING_URI=arn:aws:sagemaker:\u0026lt;region\u0026gt;:\u0026lt;account-id\u0026gt;:mlflow-app/app-\u0026lt;app-id\u0026gt; # Start import import-all --input-dir mlflow-export Bước 7: Xác thực kết quả di chuyển Để xác nhận việc di chuyển thành công, hãy xác minh rằng các tài nguyên MLflow của bạn đã được chuyển chính xác:\nSau khi tập lệnh import-all đã di chuyển các thí nghiệm, lần chạy và các đối tượng khác sang máy chủ theo dõi mới, bạn có thể bắt đầu xác minh thành công của việc di chuyển bằng cách mở bảng điều khiển của Serverless MLflow App (đã mở ở Bước 2) và xác minh rằng: Các tài nguyên MLflow đã xuất hiện diện với tên và metadata gốc. Lịch sử chạy đầy đủ với các chỉ số (metrics) và tham số. Các tạo tác mô hình (model artifacts) có thể truy cập và tải xuống được. Thẻ (tags) và ghi chú được bảo tồn. Hình 5: Giao diện người dùng MLflow, trang đích sau khi di chuyển\nBạn có thể xác minh quyền truy cập bằng lập trình bằng cách bắt đầu một SageMaker notebook mới và chạy mã sau: import mlflow # Set the tracking URI to your MLflow App ARN mlflow.set_tracking_uri(\u0026#39;arn:aws:sagemaker:\u0026lt;region\u0026gt;:\u0026lt;account-id\u0026gt;:mlflow-app/app-\u0026lt;app-id\u0026gt;\u0026#39;) # List all experiments experiments = mlflow.search_experiments() for exp in experiments: print(f\u0026#34;Experiment Name: {exp.name}\u0026#34;) # Get all runs for this experiment runs = mlflow.search_runs(exp.experiment_id) print(f\u0026#34;Number of runs: {len(runs)}\u0026#34;) Các cân nhắc Khi lập kế hoạch di chuyển MLflow, hãy xác minh môi trường thực thi của bạn (cho dù là EC2, máy cục bộ hay SageMaker notebooks) có đủ dung lượng lưu trữ và tài nguyên tính toán để xử lý khối lượng dữ liệu của máy chủ theo dõi nguồn. Mặc dù việc di chuyển có thể chạy trong nhiều môi trường khác nhau, hiệu suất có thể thay đổi dựa trên kết nối mạng và tài nguyên sẵn có. Đối với các cuộc di chuyển quy mô lớn, hãy cân nhắc chia nhỏ quy trình thành các lô nhỏ hơn (ví dụ: từng thí nghiệm riêng lẻ).\nDọn dẹp Một máy chủ theo dõi MLflow được quản lý bởi SageMaker sẽ phát sinh chi phí cho đến khi bạn xóa hoặc dừng nó. Việc tính phí cho các máy chủ theo dõi dựa trên thời gian máy chủ đã chạy, kích thước đã chọn và lượng dữ liệu được ghi vào máy chủ theo dõi. Bạn có thể dừng các máy chủ theo dõi khi chúng không được sử dụng để tiết kiệm chi phí, hoặc bạn có thể xóa chúng bằng API hoặc giao diện người dùng SageMaker Studio. Để biết thêm chi tiết về giá cả, hãy tham khảo Giá Amazon SageMaker.\nKết luận Trong bài viết này, chúng tôi đã trình bày cách di chuyển một máy chủ theo dõi MLflow tự quản lý sang SageMaker với MLflow bằng cách sử dụng công cụ mã nguồn mở MLflow Export Import. Việc di chuyển sang một Serverless MLflow App trên Amazon SageMaker AI giúp giảm chi phí vận hành liên quan đến việc duy trì cơ sở hạ tầng MLflow trong khi cung cấp sự tích hợp liền mạch với các dịch vụ AI/ML toàn diện trong SageMaker AI.\nĐể bắt đầu quá trình di chuyển của riêng bạn, hãy làm theo hướng dẫn từng bước ở trên và tham khảo tài liệu được dẫn chứng để biết thêm chi tiết. Bạn có thể tìm thấy các mẫu mã và ví dụ trong kho lưu trữ AWS Samples GitHub. Để biết thêm thông tin về các khả năng của Amazon SageMaker AI và các tính năng MLOps khác, hãy truy cập tài liệu Amazon SageMaker AI.\n"},{"uri":"https://kphuong08.github.io/Report/vi/4-eventparticipated/4.1-event1/","title":"Event 1","tags":[],"description":"","content":"Bài thu hoạch “Cloud Day VietNam 2025: Ho Chi Minh City Connect Edition for Builders” Mục Đích Của Sự Kiện Chia sẻ các xu hướng về AI Các giải pháp ứng dụng AWS vào trong doanh nghiệp Chia sẻ vè phân tích dữ liệu và trí tuệ nhân tạo trong thúc đẩy phát triển Di chuyển, hiện đại hóa và xây dựng ứng dụng trên AWS Bài thu hoạch này tập trung về nội dung Migrate \u0026amp; Mordenization trong sự kiện\nDanh Sách Diễn Giả Nguyễn Văn Hải - Director of Software Engineering, Techcombank \u0026amp; Sơn Đỗ - Technical Account Manager, AWS Phúc Nguyễn - Solutions Architect, AWS \u0026amp; Alex Trần - Giám đốc AI, OCB Hùng Hoàng - Customer Solutions Manager, AWS Taiki Đặng - Solutions Architect, AWS Nguyễn Mạnh Tuyên - THead of Data Application, LPBank Securities Nguyễn Minh Ngân - AI Specialist, OCB Nguyễn Thế Vinh - Co-Founder \u0026amp; CTO, Ninety Eight Nội Dung Nổi Bật Quá trình di chuyển và hiện đại hóa quy mô lớn lên AWS Đưa ra bài toán, vấn đề của doanh nghiệp trong việc mở rộng hạ tầng để đáp ứng nhu cầu khách hàng Các động lực và quá trình dẫn đến quyết định di chuyển từ on-prem lên cloud Quá trình di chuyển các tài nguyên -\u0026gt; những tài nguyên đưa lên cloud trước và sau Hiện đại hóa ứng dụng với công cụ Generative AI-Powered Khám phá cách Amazon Q Developer chuyển đổi vòng đời phát triển phần mềm (SDLC) thông qua khả năng hoạt động như một tác nhân trên các nền tảng AWS Console, IDE, CLI và DevSecOps Chia sẻ cách công cụ GenAI giúp tăng tốc phát triển phần mềm, tự động viết tài liệu, test và ảo Thảo luận với nhóm diễn giả: Chuyển đổi kinh doanh Các chia sẻ từ chuyên gia về ứng dụng AI trong doanh nghiệp Các case-study thực tế về hiện đại hóa ứng dụng để tăng tốc và đổi mới trong doanh nghiệp Chuyển đổi VMware với AI-driven cloud modernisation Chi sẻ cách AWS Transform giúp di chuyển nhanh chóng, an toàn và tiết kiệm chi phí từ VMware lên cloud Lộ trình hiện đại hóa lên EKS, RDS và serverless sau khi triển khai AWS security at scale: Từ development đến production Giới thiệu AWS Sercurity Hub Chia sẻ cách nâng cao bảo mật cloud ở quy mô lớn Cách tích hợp GenAI vào phân tích và tự động hóa vận hành bảo Những Gì Học Được Xu hướng chuyển đổi của công nghệ hiện nay GenAI: sự phát triển mạnh mẽ của AI và xu hướng ứng dụng nó vào trong doanh nghiệp Migrate \u0026amp; Modernization: xu hướng di chuyển và hiện đại hóa công nghệ trong doanh nghiệp Sercurity: cùng với sự phát triển và chuyển đổi thì bảo mật là cần thiết để bảo vệ dữ liệu, ứng dụng và công nghệ Tiếp cận chuyển đổi và hiện đại hóa Động lực: dựa vào bài toán doanh nghiệp hiện tại và tương lai, nhân lực, trình độ và sự ủng hộ Kế hoạch và nhân tố: đưa ra hướng đi phù hợp với tình hình doanh nghiệp hiện tại và có một kế hoạch chi tiết Chiến lược hiện đại hóa: có một kế hoạch cụ thể về những phần dịch chuyển, cách dịch chuyển và lúc dịch chuyển Các công cụ GenAI và ứng dụng Biết thêm được các công cụ GenAI (Amazon Q) và cách ứng dụng nó vào ứng dụng để tăng tốc quá trình phát triển ứng dụng, phần Hiểu thêm khả năng của Q Developer trong việc hiểu các cơ sở mã phức tạp, đề xuất các tối ưu hóa và tự động hóa các tác vụ thường xuyên trong suốt vòng đời phát triển. Bảo mật trong cloud Biết thêm về các quy tắc bảo mật trong cloud, cách tích hợp các nguyên tắc bảo mật ngay từ khâu thiết kế vào toàn bộ quy trình phát triển và sử dụng các khả năng phát hiện và phản hồi nâng cao Khám phá cách GenAI tăng cường phân tích bảo mật và tự động hóa các hoạt động Tìm hiểu về AWS Sercurity Hub trong việc bảo mật Ứng Dụng Vào Công Việc Công cụ GenAI: ứng dụng trong việc hỗ trợ phát triển, bảo mật Bảo mật: ứng dụng các quy tắc bảo mật vào ứng dụng Trải nghiệm trong event Tham gia event “Cloud Day VietNam 2025” là một trải nghiệm rất bổ ích, giúp tôi học hỏi thêm về GenAI, bảo mật, quá trình Migrate \u0026amp; Modernization của ứng dụng và hiểu thêm về các case-study thực tế từ các doanh nghiệp. Một số trải nghiệm nổi bật:\nHọc hỏi từ các diễn giả có chuyên môn cao Các diễn giả đến từ AWS và các tổ chức công nghệ lớn đã chia sẻ về những gì thực tế nhất mà các doanh nghiệp đang vận hành Qua các case study thực tế, tôi hiểu rõ hơn về GenAI và Migrate \u0026amp; Modernization trong các úng dụng thực tế. Kết nối và trao đổi Event tạo cơ hội trao đổi trực tiếp với các chuyên gia, các bạn có chung đam mê giúp tôi có thêm những kiến thức cũng như hiểu rõ hơn về xu hướng công nghệ hiện tại. Qua các ví dụ thực tế, tôi biết thêm được về GenAI, Migrate \u0026amp; Modernization là những hướng đi công nghệ mà cách doanh nghiệp đang hướng tới Bài học rút ra GenAI đang phát triển rất vượt trội và đang càng được nhiều doanh nghiệp ứng dụng vào hệ thống của họ Chiến lược di chuyển và hiện đại hóa cần đánh giá và lên kế hoạch một cách chi tiết, không nên vội vàng chuyển đổi toàn bộ hệ thống. Các công cụ AI như Amazon Q Developer có thể hỗ trợ trong việc tăng tốc phát triển phần mềm Tổng thể, sự kiện không chỉ cung cấp kiến thức kỹ thuật mà còn giúp tôi biết thêm về xu hướn AI và chuyển đổi \u0026amp; hiện đại hóa trong doanh nghiệp\n"},{"uri":"https://kphuong08.github.io/Report/vi/4-eventparticipated/4.2-event2/","title":"Event 2","tags":[],"description":"","content":"Bài thu hoạch “Secure Your Applications: AWS Perimeter Protection Workshop” Mục Đích Của Sự Kiện Chia sẻ CloudFront, WAF, AWS Shield Giới thiệu về cách thiết kế và tối ưu hóa việc phân phối nội dung toàn cầu với CloudFront Phương pháp bảo vệ các ứng dụng web khỏi các mối đe dọa bằng cách sử dụng AWS WAF Thực hành bảo mật và tối ưu hóa ứng dụng Web Danh Sách Diễn Giả Nguyen Gia Hung - Head of Solutions Architect, AWS Julian Ju - Senior Edge Services Specialist Solutions Architect, AWS Nội Dung Nổi Bật Giới thiệu về CloudFront Hoạt động: hoạt động dựa trên mạng lưới các điểm hiện diện (PoPs) để định tuyến traffic đến nơi gần người dùng nhất. Connectivity \u0026amp; Protocols: HTTP/3 Multiplexing, TCP Optimization (Persistent Connection, Connection Pooling, TCP Window Scaling), AWS Global Backbone Origin cloaking: ẩn server gốc (S3 \u0026ldquo;block all\u0026rdquo; - best practice) Access Control: Signed URL/Cookies, Geographic Restriction Performance: multi-layer cache, request collapsing, TTL (Time-to-Live) Reliability: CloudFront Origin Failover (Request Level), DNS Failover (Route 53 Global Scale), Logic tại Edge Observability: CloudWatch RUM (Real User Monitoring), nternet Monito Các vấn đề về bảo mật trong ứng dụng Các cuộc tấn công DDoS vào hạ tầng mạng Các lỗ hổng ứng dụng gây nguy cơ bị tấn công Bot traffic (fake client) làm hao hụt tài nguyên Các cuộc tấn công brute-force và flood Giới thiệu về WAF và cách bảo vệ ứng AWS Shield: bảo vệ layer3-4, tự động phát hiện và chặn các cuộc tấn công DDoS vào hạ tầng mạng. AWS WAF: bảo vệ layer7, chặn các lỗ hổng ứng dụng (CVE), SQLi, XSS Bot Control: ngăn chặn bot traffic (fake client) gây tốn chi phí và sai lệch dữ liệu. Rate limit: giới hạn số lượng request để chống brute-force hoặc flood. Những Gì Học Được AWS CloudFront Hiểu thêm về cách hoạt động của Cloudfront, các case-study trong doanh nghiệp với CloudFront Biết được cách sử dụng CloudFront và cách tối ưu ứng dụng web với CloudFront Bảo mật với WAF Biết được các nguy cơ và lỗ hổng bảo mật Tìm hiểu được cách hoạt động của WAF và cách WAF ngăn chặn các cuộc tấn công bảo mật Biết cách sử dụng WAF để ngăn chặn các lỗ hổng và các cuộc tấn công cơ bản Ứng Dụng Vào Công Việc Áp dụng CloudFront trong triển khai web: Sử dụng CloudFront cho việc tối ưu ứng dụng Web và triển khai theo hướng Serverless, tối ưu chi phí với những web đơn giản không cần xử lý nhiều Áp dụng WAF trong bảo mật: sử dụng WAF cho việc bảo mật luỗng dữ liệu trong hệ thống, với việc cho phép những luồng dữ liệu tin cậy đi qua và chặn nhựng luồng dữ liệu đáng ngờ Trải nghiệm trong event Tham gia workshop “Secure Your Applications: AWS Perimeter Protection Workshop ” là một trải nghiệm rất bổ ích, giúp tôi có thêm kiến thức về CDN, tối ưu việc triển khai ứng dụng Web trên internet và bảo mật trong cloud. Một số trải nghiệm nổi bật:\nHọc hỏi từ các diễn giả có chuyên môn cao Các diễn giả đến từ AWS đã chia sẻ best practices trong tối ưu thiết kế, bảo mật ứng dụng Qua các case study thực tế, tôi hiểu rõ hơn cách áp dụng CloudFront và AWS WAF vào các trường hợp thực tế. Trải nghiệm kỹ thuật thực tế Workshop thực hành triển khai một ứng dụng Web trên CloudFront giúp tôi hiểu về cách CloudFront hoạt động Thực hành bảo mật bằng WAF với nhiều kịch bản khác nhau giúp tôi hiểu về cách WAF bảo mật và triển khai bảo mật theo nhu cầu của mình trên WAF Kết nối và trao đổi Việc tham gia nghe và thảo luận với các diễn giả cũng như bạn đồng tham dự, giúp tôi kết nối và học hỏi thêm về những dịch vụ trên AWS cụ thể là CloudFront và WAF Việc thực hành triển khia CloudFront cũng như WAF dưới sự hướng dẫn của diễn giả giúp tôi biết thêm về cách thức cũng như hiểu thêm về cách hoạt động của những dịch vụ này Bài học rút ra CloudFront: một dịch vụ CDN có thể giúp ích trong viêc tối ưu triển khai ứng dụng Web trên Internet WAF: dịch vụ bảo mật giúp người dùng có thể ngăn chặn các lỗ hổng bảo mật cũng như các cuộc tấn công mạng cho ứng dụng Tổng thể, sự kiện không chỉ cung cấp kiến thức kỹ thuật mà còn giúp tôi biết thêm về những dịch vụ hỗ trợ trong việc triển khai ứng Web một cách hiệu quả, tối ưu chi phí và bảo mật hơn.\n"},{"uri":"https://kphuong08.github.io/Report/vi/5-workshop/5.1-workshop-overview/","title":"Giới thiệu","tags":[],"description":"","content":"Tự động hóa quy trình MLOps trên AWS sử dụng SageMaker theo hướng Serverless MLOps Là sự kết hợp giữa Machine Learning, DevOps và Data Engineering. Là một quy trình tự động hóa khép kín: từ lúc lấy dữ liệu (Data Ingestion), huấn luyện (Training), đánh giá (Evaluation) cho đến triển khai (Deployment) và giám sát (Monitoring). Mục tiêu là giảm thiểu thao tác thủ công và tăng tốc độ đưa model ra thị trường. SageMaker AI Là nền tảng toàn diện của AWS giúp xây dựng, huấn luyện và triển khai các mô hình ML. Trong bài lab này, chúng ta sẽ tận dụng các tính năng hiện đại nhất của SageMaker: SageMaker Training: Sử dụng Spot Instances để tiết kiệm chi phí huấn luyện. SageMaker Serverless Inference: Triển khai model API mà không cần quản lý server, tự động scale về 0 khi không sử dụng (Cost Optimization). SageMaker Pipelines (hoặc Step Functions): Để điều phối luồng công việc. "},{"uri":"https://kphuong08.github.io/Report/vi/1-worklog/","title":"Nhật ký công việc","tags":[],"description":"","content":"Đây là worklog các công việc đã làm theo các tuần với nội dung như sau:\nTuần 1: Làm quen với AWS và các dịch vụ cơ bản trong AWS\nTuần 2: Học các dịch vụ AWS cơ bản và thực hành\nTuần 3: Học và tìm hiểu về đồ án\nTuần 4: Lên kế hoạch và thử nghiệm tính khả thi\nTuần 5: Học, tìm hiểu và thử sử dụng các dịch vụ liên quan\nTuần 6: Xây dụng kiến trúc và luồng dữ liệu\nTuần 7: Kiểm thử cách sử dụng các dịch vụ và điều chỉnh\nTuần 8: Xây dựng hạ tầng cơ bản\nTuần 9: Viết script và các function\nTuần 10: Triển khai và kiểm tra\nTuần 11: Đánh giá và viết báo cáo\nTuần 12: Viết báo cáo\n"},{"uri":"https://kphuong08.github.io/Report/vi/5-workshop/5.3-training-flow/5.3.1-lamda-function/","title":"Tạo lambda function","tags":[],"description":"","content":" Mở Amazon Lambda console Trong thanh điều hướng, chọn Function, click Create Function: Trong Create function console: Đặt tên cho endpoint: Trigger-Training-Job Chọn Runtime: Python 3.14 Ở phần permission chọn Use an existing role và chọn role vừa tạo ban đầu Nhấn Create function và Lambda sẽ được tạo\nTrước đó hãy update policy của role để Lamda có thể sử dụng.\nVào IAM console mục Role chọn role vừa tạo.\nỞ phần Trust relationship nhấn Edit trust policy sau đó thêm statement cho phép Lambda và S3 vào.\nNhấn Update policy và policy cho role sẽ được update\nSau khi tạo function xong thì dán mã sau vào source code\nimport boto3 import os import time sm = boto3.client(\u0026#39;sagemaker\u0026#39;) def lambda_handler(event, context): # 1. Parse thông tin từ sự kiện S3 record = event[\u0026#39;Records\u0026#39;][0] bucket = record[\u0026#39;s3\u0026#39;][\u0026#39;bucket\u0026#39;][\u0026#39;name\u0026#39;] key = record[\u0026#39;s3\u0026#39;][\u0026#39;object\u0026#39;][\u0026#39;key\u0026#39;] # 2. Định nghĩa tên Job duy nhất job_name = f\u0026#34;serverless-mlops-{int(time.time())}\u0026#34; # 3. Cấu hình Training Job # Sử dụng Scikit-learn container có sẵn của AWS image_uri = \u0026#34;683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:0.23-1-cpu-py3\u0026#34; role = os.environ.get(\u0026#39;ROLE_ARN\u0026#39;) # Cần set biến môi trường này print(f\u0026#34;Starting training job {job_name} using data from s3://{bucket}/{key}\u0026#34;) sm.create_training_job( TrainingJobName=job_name, HyperParameters={ \u0026#39;sagemaker_program\u0026#39;: \u0026#39;train.py\u0026#39;, \u0026#39;sagemaker_submit_directory\u0026#39;: f\u0026#34;s3://{bucket}/code/source.tar.gz\u0026#34; }, AlgorithmSpecification={ \u0026#39;TrainingImage\u0026#39;: image_uri, \u0026#39;TrainingInputMode\u0026#39;: \u0026#39;File\u0026#39;, }, RoleArn=role, InputDataConfig=[{ \u0026#39;ChannelName\u0026#39;: \u0026#39;train\u0026#39;, \u0026#39;DataSource\u0026#39;: { \u0026#39;S3DataSource\u0026#39;: { \u0026#39;S3DataType\u0026#39;: \u0026#39;S3Prefix\u0026#39;, \u0026#39;S3Uri\u0026#39;: f\u0026#34;s3://{bucket}/{key}\u0026#34;, \u0026#39;S3DataDistributionType\u0026#39;: \u0026#39;FullyReplicated\u0026#39; } } }], OutputDataConfig={\u0026#39;S3OutputPath\u0026#39;: f\u0026#34;s3://{bucket}/output/\u0026#34;}, ResourceConfig={\u0026#39;InstanceType\u0026#39;: \u0026#39;ml.m5.large\u0026#39;, \u0026#39;InstanceCount\u0026#39;: 1, \u0026#39;VolumeSizeInGB\u0026#39;: 5}, StoppingCondition={\u0026#39;MaxRuntimeInSeconds\u0026#39;: 3600} ) return {\u0026#34;statusCode\u0026#34;: 200, \u0026#34;body\u0026#34;: job_name} Nhấn Deploy\nNhấn qua tab Configuration　để thêm Enviroment variabled\nClick Edit sau đó Add enviroment variables thêm:\nKey: ROLE_ARN Value: là ARN của role ở trên Sau đó nhấn Save "},{"uri":"https://kphuong08.github.io/Report/vi/1-worklog/1.1-week1/","title":"Worklog Tuần 1","tags":[],"description":"","content":"Mục tiêu tuần 1: Tham gia cộng đồng, bước đầu làm quen với các thành viên trong First Cloud Journey. Tạo account AWS, tìm hiểu cơ bản cách sử dụng console, CLI Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ 1/9/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ 2/09/2025 2/09/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 3/09/2025 3/09/2025 https://000001.awsstudygroup.com/ 5 - Tạo Budget và IAM + Cấu hình MFA 4/09/2025 4/09/2025 https://000001.awsstudygroup.com/\u003e 6 - Tìm hiểu cơ bản các dịch vụ đơn giản: EC2, VPC, S3,\u0026hellip; 5/09/2025 5/09/2025 https://cloudjourney.awsstudygroup.com/1-explore/ Kết quả đạt được tuần 1: Kết nối và làm quen được các bạn trong cộng đồng\nĐã tạo và cấu hình AWS Free Tier account thành công.\nTạo Budget để quản lý account, MFA để bảo mật và IAM\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách các dịch vụ Kết hợp giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n"},{"uri":"https://kphuong08.github.io/Report/vi/1-worklog/1.2-week2/","title":"Worklog Tuần 2","tags":[],"description":"","content":"Mục tiêu tuần 2: Tìm hiểu các dịch vụ của AWS Hiểu được cách hoạt động cũng như luồng dữ liệu của các dịch vụ Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu kiến trúc, các thành phần AWS: + Compute + Storage + Networking + Database 8/09/2025 8/09/2025 3 - Tìm hiểu dịch vụ EC2: + Cách tạo instance + Cách SSH + Các instance type + Thực hành: Tạo EC2 SSH vào EC2 Tạo EC2 với user data 9/09/2025 9/09/2025 \u0026lt;https://000004.awsstudygroup.com/ 4 - Tìm hiểu VPC: + Region, AZ + Subnet, route table, sercurity group + Internet gateway, nat gateway + Thực hành: Tạo subnet, route table Tạo sercurity group Tạo internet gateway, nat gateway Tạo VPC hoàn chỉnh với đủ private, public subnet, connect internet-public-private 10/09/2025 10/09/2025 https://000003.awsstudygroup.com/ 5 - Tìm hiểu các loại database: + S3 + RDS + DynamoDB - Tìm hiểu Elastic IP 11/09/2025 11/09/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo VPC và EC2 instance + Kết nối SSH + Chạy web static đơn giản và test truy cập 12/09/2025 12/09/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 2: Hiểu cách thành phần trong AWS:\nCompute Storage Networking Database Làm quen với việc tạo VPC, EC2\nLàm quen với network trong AWS (sercurity group, route table, nat, internet gateway)\nTìm hiểu được các database, lưu trữ trong AWS:\nTạo và host được một web static cơ bản bằng EC2 và có thể truy cập từ bên ngoài được\n"},{"uri":"https://kphuong08.github.io/Report/vi/1-worklog/1.3-week3/","title":"Worklog Tuần 3","tags":[],"description":"","content":"Mục tiêu tuần 3: Học và thực hành các dịch vụ của AWS Tìm hiểu các dịch vụ AI cho project Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các dịch vụ AI của AWS \u0026amp;emsp + Tổng quan AI trong AWS + Giới thiệu về Bedrock + Giới thiệu về Nova + Giới thiệu Amazon Q + Giới thiệu Sagemaker 15/09/2025 15/09/2025 3 - Tìm hiểu sơ lược về các dịch vụ + Loại, hỗ trợ + Kiến trúc + Giá cả 16/09/2025 16/09/2025 https://cloudjourney.awsstudygroup.com/ 4 - Đọc và tìm hiểu về MLOps và MLOps được hỗ trợ như thế nào trên AWS 17/09/2025 17/09/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu về cơ sở dữ liệu: + S3, RDS, DynamoDB - Thực hành: + Tạo, xóa, sửa + Kết nối cơ sở dữ liệu với website đơn giản 18/09/2025 18/09/2025 https://cloudjourney.awsstudygroup.com/ 6 - Tìm hiểu EC2 ABL và auto scaling Thực hành: + Tạo EC2 instance + Kết nối đến EC2 qua ABL + Tạo auto scaling cho EC2 19/09/2025 19/09/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 3: Tìm hiểu được sơ lược các dịch vụ AI của AWS\nBecdrock Nove Amzaon Q Sagemaker Tìm hiểu được cơ sở dữ liệu của AWS và thực hành tạo các cơ sở dữ liệu\nKết nối cơ sở dữ liệu với EC2 cho một website đơn giản\nTìm hiểu ABL và auto scaling cho EC2\n"},{"uri":"https://kphuong08.github.io/Report/vi/1-worklog/1.4-week4/","title":"Worklog Tuần 4","tags":[],"description":"","content":"Mục tiêu tuần 4: Học thêm một vài dịch vụ AWS Tìm hiểu và quyết định loại dịch vụ AI được sử dụng Lên kế hoạch cho project Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Thống kê các chức năng, giá cả,\u0026hellip; của các dịch vụ AI đã tìm hiểu - Quyết định loại dịch vụ sử dụng và cách sử dụng cũng như triển khai 22/09/2025 22/09/2025 3 - Tìm hiểu cơ bản về Serverless và Microservice 23/09/2025 23/08/2025 4 - Tìm hiểu vể Lambda: + Cách sử dụng + Luồng hoạt động 24/09/2025 24/09/2025 https://000022.awsstudygroup.com/ 5 - Thực hành sử dụng Lamda: + Tạo function + Tạo trigger 25/09/2025 25/09/2025 https://000022.awsstudygroup.com/ 6 - Viết kế hoạch cho project + Các dịch vụ cần tìm hiểu + Các thành phần cần làm 26/08/2025 26/09/2025 Kết quả đạt được tuần 4: Hiểu thêm về các dịch vụ AI\nQuyết định loại dịch vụ sử dụng cho project\nHiểu sơ lược về Serverless và Microservice\nBiết thêm về Lambda và biết cách tạo lambda function\nLên kế hoạch cho project:\nCác dịch vụ cần tìm hiểu Các thành phần "},{"uri":"https://kphuong08.github.io/Report/vi/1-worklog/1.5-week5/","title":"Worklog Tuần 5","tags":[],"description":"","content":"Mục tiêu tuần 5: Học, tìm hiểu cách sử dụng của Sagemaker AI Tìm hiểu thêm về các dịch vụ liên quan Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với Sagemaker AI: \u0026amp;emsp + Kiến trúc \u0026amp;emsp + Luồng hoạt động \u0026amp;emsp + Cách dịch vụ hỗ trợ trong Sagemaker \u0026amp;emsp + Hướng Serverless trong Sagemaker 29/09/2025 29/09/2025 3 - Tìm hiểu Cloudwatch - Thực hành tạo một CloudWatch alarm 30/09/2025 30/09/2025 https://000008.awsstudygroup.com/ 4 - Tìm hiểu EventBridge - Thực hành tạo một EventBridge trigger để kích hoạt Lambda theo giờ 1/10/2025 1/10/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu SageMaker Studio, JumbStart và deploy thử một model trong JumpStart 2/10/2025 2/10/2025 6 - Tìm hiểu về GithubAction 15/08/2025 3/10/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 5: Biết thêm về SageMaker AI\nSagemaker Studio JumbStart Tìm hiểu được cách deploy một model trong Sagemaker\nBiết thêm về CloudWatch và sử dụng được CloudWatch để theo dõi log\nBiết thêm về EventBridge và sử dụng để trigger\nHọc thêm về GithubAction để xây dựng CI/CD\n"},{"uri":"https://kphuong08.github.io/Report/vi/1-worklog/1.6-week6/","title":"Worklog Tuần 6","tags":[],"description":"","content":"Mục tiêu tuần 6: Xây dựng được kiến trúc project, luồng dữ liệu giữa các service Cách kết nối các service với nhau Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu các flow giữa các service - Cách kết nối Lambda đến Sagemaker - Cách EventBridge trigger Lambda 6/10/2025 6/10/2025 3 - Xây dựng từng flow dữ liệu - Xây dựng kiến trúc cho từng flow 7/10/2025 7/10/2025 4 - Tìm hiểu cách triển khai Serverless endpoint trong SageMaker 8/10/2025 8/10/2025 5 - Tìm hiểu GithubAction kết nối đến các dịch vụ trong AWS 9/10/2025 9/10/2025 6 - Xây dựng flow dữ liệu từ Github đến AWS 10/10/2025 10/10/2025 Kết quả đạt được tuần 6: Hiểu thêm về flow giữa các service trong AWS\nBiết thêm về cách GithubAction kết nối đến AWS\nBiết được cách triển khai Serverless endpoint trong Sagemaker\nXây dựng được kiến trúc sơ bộ và flow dữ liệu\n"},{"uri":"https://kphuong08.github.io/Report/vi/1-worklog/1.7-week7/","title":"Worklog Tuần 7","tags":[],"description":"","content":"Mục tiêu tuần 7: Xây dựng hạ tầng bằng console Triển khai các flow thủ công Điều chỉnh các thông số, dịch vụ nếu cần Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tạo S3 và Eventbridge - Trigger sự kiện upload lên S3 với EventBridge 13/10/2025 13/10/2025 3 - Thử deploy thủ công model và endpoint trên Sagemaker - Tạo lambda function để tự động deploy 12/08/2025 14/10/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo data và model để thử chạy thủ công training job trên Sagemaker 15/10/2025 15/10/2025 5 - Tạo git workflow và chạy thử trigger với git 16/10/2025 16/10/2025 6 - Điều chỉnh mô hình và luồng dữ liệu giữa các service 17/10/2025 17/10/2025 Kết quả đạt được tuần 7: Triển khai thủ công hạ tầng trên console\nHiểu thêm về cách các service hoạt động\nTạo thủ công các flow giữa các service\nTạo được flow trigger bằng git\nĐiều chỉnh lại mô hình hệ thống\n"},{"uri":"https://kphuong08.github.io/Report/vi/1-worklog/1.8-week8/","title":"Worklog Tuần 8","tags":[],"description":"","content":"Mục tiêu tuần 8: Xây dựng được hạ tầng bằng terraform Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Liệt kê các module cần thiết và chia cấu trúc thư mục 20/10/2025 20/10/2025 3 - Viết các module + S3 + Eventbridge 21/10/2025 21/10/2025 4 - Viết các module + Cloudwatch + IAM 22/10/2025 22/10/2025 5 - Triển khai thử và fix bug 23/10/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Viết module lambda trigger training và deploy 24/10/2025 24/10/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 8: Tạo được cấu trúc thư mục của project\nViết được module cơ bản của hạ tầng hệ thống\nS3 IAM Cloudwatch Eventbridge Lambda Đã triển khai thử và còn bug\n"},{"uri":"https://kphuong08.github.io/Report/vi/1-worklog/1.9-week9/","title":"Worklog Tuần 9","tags":[],"description":"","content":"Mục tiêu tuần 9: Viết được hạ tầng hệ thống Viết đuọc function của lambda Viết được script của model và data Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Viết script function lambda trigger training 27/10/2025 27/10/2025 3 - Viết function lambda redeploy 28/10/2025 28/10/2025 4 - Triển khai thử và fix 29/10/2025 29/10/2025 5 - Viết script chuẩn bị model và data 30/10/2025 30/10/2025 6 - Viết git workflows để triển khai thử và fix bug 31/10/2025 31/10/2025 Kết quả đạt được tuần 9: Viết được module lambda Viết được 2 function lambda Đã triển khai thử nhưng còn nhiều bug "},{"uri":"https://kphuong08.github.io/Report/vi/2-proposal/","title":"Bản đề xuất","tags":[],"description":"","content":"Automate MLOps Tự động hóa quy trình Fine-tune và Deployment model trên AWS theo hướng Serverless 1. Tóm tắt điều hành Serverless MLOps Pipeline được thiết kế nhằm giải quyết bài toán tối ưu hóa chi phí và tự động hóa quy trình huấn luyện (fine-tune) cũng như triển khai (deploy) mô hình máy học. Hệ thống tập trung vào việc loại bỏ các thao tác thủ công của kỹ sư dữ liệu, chuyển đổi từ mô hình quản lý hạ tầng truyền thống sang kiến trúc Event-driven và Serverless trên AWS.\nQuy trình MLOps này cho phép tự động kích hoạt việc huấn luyện lại (re-training) khi có dữ liệu mới trên S3, thực hiện đánh giá (evaluation) tự động và triển khai mô hình lên SageMaker Serverless Inference. Giải pháp giúp giảm thiểu chi phí vận hành xuống mức thấp nhất nhờ tận dụng EC2 Spot Instances cho quá trình training và cơ chế auto-scaling về 0 của Serverless Endpoint cho quá trình inference.\n2. Tuyên bố vấn đề Vấn đề hiện tại\nQuy trình phát triển và vận hành mô hình ML hiện tại gặp nhiều trở ngại:\nThủ công và rời rạc: Kỹ sư phải chạy lệnh thủ công để train, evaluate và deploy. Code base khó bảo trì. Lãng phí tài nguyên: Sử dụng các instance on-demand đắt đỏ và thường xuyên quên tắt sau khi train xong. Endpoint chạy liên tục 24/7 dù không có request. Thiếu kiểm soát chất lượng: Logic đánh giá (evaluation) sơ sài hoặc là mock (giả lập), dẫn đến rủi ro khi deploy model kém chất lượng lên production. Giải pháp\nXây dựng một pipeline CI/CD/CT (Continuous Training) hoàn chỉnh:\nTraining: Sử dụng SageMaker Training Jobs với Spot Instances để giảm chi phí huấn luyện (tiết kiệm 50-80%). Evaluation: Tích hợp script đánh giá thật, so sánh metrics (Accuracy, F1) với threshold trước khi chấp nhận model. Inference: Chuyển sang SageMaker Serverless Endpoints, chỉ tính phí khi có request và miễn phí khi nhàn rỗi. Automation: Sử dụng Amazon EventBridge và GitHub Actions để điều phối quy trình từ lúc có dữ liệu mới đến khi deploy xong. Lợi ích và hoàn vốn đầu tư (ROI)\nGiải pháp mang lại hiệu quả kinh tế rõ rệt và giải phóng sức lao động cho kỹ sư AI/ML. Chi phí vận hành ước tính chỉ khoảng $3.30/tháng cho một kịch bản tiêu chuẩn (so với hàng chục USD nếu dùng hạ tầng tĩnh). Thời gian từ lúc có dữ liệu đến lúc model được update giảm từ vài ngày xuống vài giờ hoàn toàn tự động. Hệ thống CloudWatch Monitoring giúp phát hiện sự cố training hoặc inference ngay lập tức.\n3. Kiến trúc giải pháp Nền tảng áp dụng kiến trúc Event-driven Serverless để quản lý vòng đời của mô hình Machine Learning. Dữ liệu huấn luyện (CSV/JSON) được upload lên S3 sẽ kích hoạt chuỗi sự kiện tự động, từ training, đánh giá đến deploy.\nDịch vụ AWS sử dụng\nAmazon S3: Lưu trữ Datasets, Model Artifacts (model.tar.gz) và Training Metrics. Amazon SageMaker: Training Jobs: Chạy Fine-tuning với HuggingFace Trainer (dùng Spot Instances). Serverless Inference: Hosting model endpoint với khả năng auto-scale (cold start 1-3s). AWS Lambda: Hàm serverless thực hiện logic Redeploy endpoint khi có model mới. Amazon EventBridge: Bắt sự kiện thay đổi trạng thái (S3 upload, Training success) để điều phối luồng. Amazon CloudWatch: Dashboard giám sát training metrics, endpoint latency và error rates. Luồng dữ liệu\nIngest: Người dùng upload dataset đã chuẩn bị lên Amazon S3. Trigger: S3 Event kích hoạt quy trình (qua EventBridge hoặc Webhook tới GitHub Actions). Train: GitHub Actions khởi tạo SageMaker Training Job (sử dụng HuggingFace container trên Spot Instance). Evaluate: Sau khi train xong, pipeline chạy script tải model về, kiểm tra metrics. Nếu đạt ngưỡng (threshold), model được lưu làm candidate. Deploy: Sự kiện có model mới kích hoạt AWS Lambda, hàm này sẽ cập nhật SageMaker Serverless Endpoint. 4. Triển khai kỹ thuật Các giai đoạn triển khai\nDự án được chia thành các task cụ thể để đảm bảo tính chính xác và dễ debug:\nNghiên cứu và thử nghiệm: Nghiên cứu các dịch vụ liên quan và thử nghiệm thủ công trên console. Tính toán chi phí và kiểm tra tính khả thi: Tính toán chi phí và các hỗ trợ của các dịch vụ xem có đáp ứng được mong muốn đề ra hay không. Điều chỉnh kiến trúc để tối ưu chi phí/giải pháp: Tinh chỉnh (model, dịch vụ khác,\u0026hellip;) để đảm bảo hiệu quả Phát triển, kiểm thử, triển khai: Cấu hình, viết script, tạo cơ sở hạ tầng Clean \u0026amp; Refactor: Dọn dẹp code cũ, chuẩn hóa cấu trúc thư mục (src, ops, lambda). Data Preparation Script: Viết script prepare_data.py để split train/test và upload lên S3. Training Implementation: Cấu hình train.py sử dụng HuggingFace Trainer, tích hợp lưu metrics.json. Evaluation Logic: Viết evaluate_model.py để parse metrics và quyết định Pass/Fail dựa trên threshold. CI/CD Integration: Cấu hình GitHub Actions workflow để kết nối các bước trên. Serverless Deployment: Viết Lambda function redeploy_endpoint sử dụng Boto3 để update SageMaker Endpoint. Infrastructure as Code: Dùng Terraform để khởi tạo các tài nguyên AWS (S3, IAM Roles, Lambda).\nYêu cầu kỹ thuật\nModel: Các model HuggingFace (ví dụ: DistilBERT) cho tác vụ NLP. Compute: Training dùng ml.g4dn.xlarge (Spot); Inference dùng Serverless memory config 1024MB-3072MB. Latency: Chấp nhận Cold start 1-3s cho request đầu tiên sau thời gian nghỉ. 5. Lộ trình \u0026amp; Mốc triển khai Tháng 1: Học AWS, tìm hiểu các dịch vụ, nghiên cứu hướng triển khai Tháng 2: Thử nghiệm và điều chỉnh Tháng 3: Triển khai, kiểm thử Sau triển khai: Nghiên cứu các hướng có thể phát triển 6. Ước tính ngân sách Có thể xem chi phí trên AWS Pricing Calculator\nChi phí hạ tầng\nTraining (SageMaker Spot):~$3/tháng. Inference (SageMaker Serverless): $3/tháng. Lưu trữ (Amazon S3): ~$0.3/tháng. CloudWatch: ~$5/tháng Orchestration (Lambda + EventBridge): ~$0.01/tháng (gần như miễn phí trong Free Tier). Tổng: ~$11 USD / tháng.\n(Lưu ý: Chi phí chưa bao gồm thuế và có thể biến động nhẹ tùy thuộc vào giá Spot Instance tại thời điểm chạy).\n7. Đánh giá rủi ro Ma trận rủi ro\nSpot Instance Interruption: Training bị ngắt giữa chừng do AWS thu hồi instance. Giảm thiểu: Sử dụng Checkpointing trong code training để resume từ điểm dừng thay vì chạy lại từ đầu. Cold Start Latency: Request đầu tiên mất 1-3 giây, ảnh hưởng trải nghiệm người dùng real-time khắt khe. Giảm thiểu: Chấp nhận được với các tác vụ nội bộ hoặc không yêu cầu realtime cực cao (sub-millisecond). Có thể dùng Provisioned Concurrency nếu cần (nhưng tốn phí hơn). Model Drift: Model mới train có performance kém hơn model cũ. Giảm thiểu: Script evaluate_model.py chặn không cho deploy nếu metrics thấp hơn phiên bản hiện tại. 8. Kết quả kỳ vọng Hệ thống tự động hóa 100%: Từ lúc có data đến lúc model lên sóng không cần can thiệp thủ công. Tối ưu chi phí: Giảm chi phí hạ tầng xuống mức thấp nhất có thể cho một dự án ML. Khả năng mở rộng: Dễ dàng áp dụng kiến trúc này cho các bài toán ML khác (Computer Vision, Tabular data) chỉ bằng cách thay đổi training script. Monitoring đầy đủ: Dashboard trực quan về sức khỏe của hệ thống training và serving. "},{"uri":"https://kphuong08.github.io/Report/vi/5-workshop/5.2-prerequiste/","title":"Các bước chuẩn bị","tags":[],"description":"","content":"Tạo S3 Bucket Trước hết, chúng ta cần một nơi để lưu trữ dữ liệu huấn luyện và model artifacts.\nCác thông tin còn lại để default\nTạo thêm các folder rỗng để có thể upload file để trigger, chứa dữ liệu, lưu model và lưu script\ndata/train/: Nơi bạn sẽ upload file để trigger training. data/test/: Nơi chứa dữ liệu kiểm thử. models/: Nơi SageMaker lưu model sau khi train. code/: Nơi lưu script training (train.py) IAM permissions \u0026amp; role Vì chúng ta sử dụng kiến trúc Serverless tự động, các dịch vụ cần quyền để \u0026ldquo;nói chuyện\u0026rdquo; với nhau. Vào IAM Console, tạo một Role tên là SageMakerExecutionRole với các policy:\nAmazonSageMakerFullAccess AmazonS3FullAccess CloudWatchLogsFullAccess AWSLambda_FullAccess Lưu lại ARN của Role này để dùng ở các bước sau. Vào console của IAM, trong phần Role:\nNhấn Create để tạo role mới\nỞ đây chúng ta sẽ tạo role cho service Sagemaker và nhấn Next\nThì permission default cho role khi tạo sẽ là \u0026ldquo;AmazonSageMakerFullAccess\u0026rdquo; và nhấn Next\nNhập tên và mô tả cho role còn lại để dault và chọn Create role ở cuối trang\nRole đã được tạo. Sau đó tiến hành thêm policy cho role:\nNhấn vào role vừa tạo ở mục permission nhấn Add permission và chọn Attach policies\nSearch các role cần thiết và tick vào ô như hình trên (các policy khác tương tự)\nSau khi thêm những policy cần thiết thì nhấn Add permission\nPermission mới đã được thêm vào\nTraining Script \u0026amp; Data Chúng ta cần chuẩn bị sẵn mã nguồn training và dữ liệu mẫu ở máy local để sẵn sàng cho việc upload.\nTùy vào model sẽ có những dataset khác nhau ở đây chúng ta tạo một lệnh train đơn giản để giả lập\nTạo file train.py ở máy local với nội dung giả lập quá trình training:\nimport argparse import os import time import joblib import shutil import json # --------------------------------------------------------- # PHẦN 1: CÁC HÀM INFERENCE # --------------------------------------------------------- def model_fn(model_dir): \u0026#34;\u0026#34;\u0026#34;Load model từ ổ cứng\u0026#34;\u0026#34;\u0026#34; print(f\u0026#34;Đang load model từ: {model_dir}\u0026#34;) model_path = os.path.join(model_dir, \u0026#39;model.joblib\u0026#39;) if os.path.exists(model_path): return joblib.load(model_path) else: raise FileNotFoundError(f\u0026#34;Không tìm thấy file model tại: {model_path}\u0026#34;) def input_fn(request_body, request_content_type): \u0026#34;\u0026#34;\u0026#34; Hàm này nhận Raw Bytes từ request và chuyển thành object Python \u0026#34;\u0026#34;\u0026#34; if request_content_type == \u0026#39;application/json\u0026#39;: # Chuyển chuỗi JSON (bytes) thành Python List/Dict return json.loads(request_body) else: # Nếu gửi content-type khác, báo lỗi raise ValueError(f\u0026#34;Content type {request_content_type} chưa được hỗ trợ.\u0026#34;) def predict_fn(input_data, model): \u0026#34;\u0026#34;\u0026#34; Logic dự đoán \u0026#34;\u0026#34;\u0026#34; # Vì đây là dummy model (Dict), ta giả lập việc dự đoán # input_data lúc này đã là List/Dict nhờ hàm input_fn ở trên result = { \u0026#34;status\u0026#34;: \u0026#34;success\u0026#34;, \u0026#34;prediction_from_model\u0026#34;: model, # Model dummy của bạn \u0026#34;input_you_sent\u0026#34;: input_data } return result def output_fn(prediction, content_type): \u0026#34;\u0026#34;\u0026#34; Hàm này nhận kết quả từ predict_fn và chuyển thành JSON để trả về Client. QUAN TRỌNG: Khắc phục lỗi 500 tại đây. \u0026#34;\u0026#34;\u0026#34; # Mặc định SageMaker mong đợi accept header là application/json if content_type == \u0026#39;application/json\u0026#39;: return json.dumps(prediction) raise ValueError(f\u0026#34;Accept type {content_type} chưa được hỗ trợ.\u0026#34;) # --------------------------------------------------------- # PHẦN 2: CODE TRAINING # --------------------------------------------------------- if __name__ == \u0026#39;__main__\u0026#39;: parser = argparse.ArgumentParser() parser.add_argument(\u0026#39;--train\u0026#39;, type=str, default=os.environ.get(\u0026#39;SM_CHANNEL_TRAIN\u0026#39;)) parser.add_argument(\u0026#39;--model-dir\u0026#39;, type=str, default=os.environ.get(\u0026#39;SM_MODEL_DIR\u0026#39;)) args, _ = parser.parse_known_args() print(\u0026#34;Starting training...\u0026#34;) # time.sleep(5) dummy_model = {\u0026#34;name\u0026#34;: \u0026#34;Dummy Model\u0026#34;, \u0026#34;accuracy\u0026#34;: 99.9} save_path = os.path.join(args.model_dir, \u0026#39;model.joblib\u0026#39;) joblib.dump(dummy_model, save_path) print(f\u0026#34;Training complete. Model saved to {save_path}\u0026#34;) # Lấy đường dẫn file code đang chạy hiện tại current_script_path = __file__ # Định nghĩa đường dẫn đích trong folder output code_output_path = os.path.join(args.model_dir, \u0026#39;train.py\u0026#39;) print(f\u0026#34;Copying code from {current_script_path} to {code_output_path}\u0026#34;) shutil.copy2(current_script_path, code_output_path) # ========================================================= print(\u0026#34;Training and packaging complete.\u0026#34;) Nén file này lại thành .tar.gz\ntar -czvf source.tar.gz train.py Upload file source.tar.gz lên S3 folder code/\n"},{"uri":"https://kphuong08.github.io/Report/vi/5-workshop/5.4-endpoint/5.4.2-serverless-endpoint/","title":"Cấu hình Serverless Endpoint","tags":[],"description":"","content":"Tạo Endpoint Configuration Ở Sagemaker AI console bên thanh điều hướng chọn Deployment \u0026amp; inference Ở mục Endpoint Configuration click Create endpoint configuration Name: serverless-endpoint Type of endpoint: Serverless Click Create production variant Chọn model được tạo ở bước trên Nhấn Save Kéo ngang sang phải để có thể Edit/remove Variant Name: variant-serverless Max concurrency: 10 (đây là số lượng default, nếu muốn thêm thì cần request lên AWS để mở rộng) Nhấn Create endpoint configuration Tạo Endpoint Ở Sagemaker AI console bên thanh điều hướng chọn Deployment \u0026amp; inference Ở mục Endpoint click Create endpoint Name: endpoint-deploy-serverless Attach endpoint configuration: Use an existing endpoint configuration Chọn endpoint configuration vừa tạo ở bước trên Nhấn Select endpoint configuration Nhấn Create endpoint "},{"uri":"https://kphuong08.github.io/Report/vi/5-workshop/5.3-training-flow/5.3.2-s3-event-trigger/","title":"Tạo S3 event trigger","tags":[],"description":"","content":"Cấu hình S3 Event Trigger Tại Lambda function Chọn Add trigger　với source là S3 Trong Trigger configuration Chọn bucket: là bucket đã tạo Event typed: PUT Prefix: data/train/ (Chỉ kích hoạt khi upload vào folder này) Suffix: .csv (Chỉ kích hoạt với file csv) Sau đó tick vào \u0026ldquo;I acknowledge\u0026hellip;\u0026rdquo; và nhấn Add\nKiểm thử luồng Tạo một file data test-train.csv Upload file lên S3 path /data/train/ Di chuyển đến S3, chọn bucket vừa tạo, vào folder /data/train/\nClick Upload\nNhấn Add files chọn file data .csv đã chuẩn bị sau đó Upload lên S3\nSau khi upload thành công\nDi chuyển đến Sagemaker AI vào mục Model training \u0026amp; customization chọn Training \u0026amp; tuning jobs sẽ thấy một Job mới đang ở trạng thái InProgress. Điều này chứng tỏ Event-Driven workflow đã hoạt động thành công. "},{"uri":"https://kphuong08.github.io/Report/vi/1-worklog/1.10-week10/","title":"Worklog Tuần 10","tags":[],"description":"","content":"Mục tiêu tuần 10: Debug, fix bug code của infra, script và function Triển khai hạ tầng lên aws và test Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Fixbug, chỉnh sửa script và function 3/11/2025 3/11/2025 3 - Fixbug, chỉnh sửa code hạ tầng 4/11/2025 4/11/2025 4 - Triển khai mô hình lên aws và kiểm tra các test case 5/11/2025 5/11/2025 5 - Refactor và chỉnh sửa các lỗi nhỏ 6/11/2025 6/11/2025 6 - Fix bug và chỉnh sửa code hạ tầng và script 7/11/2025 7/11/2025 Kết quả đạt được tuần 10: Debug code hạ tầng và script Chỉnh sửa code Triển khai được mô hình lên aws và có thể test "},{"uri":"https://kphuong08.github.io/Report/vi/1-worklog/1.11-week11/","title":"Worklog Tuần 11","tags":[],"description":"","content":"Mục tiêu tuần 11: Tổng kết project Viết 1 phần báo cáo Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tổng kết và hoàn thành project - Đưa ra hướng phát triển cho project 10/11/2025 10/11/2025 3 - Viết tổng kết event đã tham gia 11/11/2025 11/11/2025 4 - Viết worklog tuần 1-4 12/11/2025 12/11/2025 5 - Viết worklog tuần 5-8 13/11/2025 13/11/2025 6 - Viết worklog tuần 9-12 14/11/2025 14/11/2025 Kết quả đạt được tuần 11: Tổng kết project và đưa ra hướng phát triển cho project\nViết một phần báo cáo\n"},{"uri":"https://kphuong08.github.io/Report/vi/1-worklog/1.12-week12/","title":"Worklog Tuần 12","tags":[],"description":"","content":"Mục tiêu tuần 12: Hoàn thành báo cáo Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Viết proposal cho project 17/11/2025 17/11/2025 3 - Viết tổng quan Workshop, outline 18/11/2025 18/11/2025 4 - Viết chi tiết Workshop 13/08/2025 19/11/2025 5 - Viết Blog 20/11/2025 20/11/2025 6 - Viết đánh giá và feedback 21/11/2025 21/11/2025 Kết quả đạt được tuần 12: Hoàn thành báo cáo "},{"uri":"https://kphuong08.github.io/Report/vi/3-blogstranslated/","title":"Các bài blogs đã dịch","tags":[],"description":"","content":"Blog 1 - Migrate MLflow tracking servers to Amazon SageMaker AI with serverless MLflow Blog này hướng dẫn kỹ thuật để di chuyển (migrate) máy chủ theo dõi MLflow tự quản lý (trên EC2 hoặc on-premises) sang Amazon SageMaker với Serverless MLflow. Giảm gánh nặng vận hành, tối ưu chi phí, tích hợp với hệ sinh thái AI/ML của SageMaker. Sử dụng MLflow Export Import và SageMaker MLflow Plugin.\n"},{"uri":"https://kphuong08.github.io/Report/vi/5-workshop/5.4-endpoint/5.4.3-deploy-invoke/","title":"Tự động deploy và kiểm thử","tags":[],"description":"","content":"Ở phần trước sẽ giúp ta hiểu thêm về cách deploy một model và endpoint trên Sagemaker ở phần này sẽ cho mọi người cách để có thể deploy một cách tự động khi có một model mới được thêm vào S3\nTự động flow tạo endpoint và deploy model Tạo Lambda function Click Create function Name: Trigger-Deployment Runtime: Python 3.14 Permission: use an existing role Chọn role đã tạo ở những bước Nhấn Create function Tạo trigger Nhấn Add trigger Source trigger: S3 Bucket: bucket chứa model Event type: PUT Prefix: output/ Subprefix: .tar.gz Nhấn Add Code Lambda Thêm đoạn code sau vào code của Lambda\nimport boto3 import time import os import logging logger = logging.getLogger() logger.setLevel(logging.INFO) sm_client = boto3.client(\u0026#39;sagemaker\u0026#39;) # CẤU HÌNH (Nên để trong Environment Variables của Lambda) # URI của container Scikit-Learn (Thay đổi theo region của bạn) # Bạn có thể lấy link này bằng lệnh: sagemaker.image_uris.retrieve(\u0026#34;sklearn\u0026#34;, region=\u0026#34;us-east-1\u0026#34;, version=\u0026#34;0.23-1\u0026#34;) CONTAINER_IMAGE_URI = \u0026#34;683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:0.23-1-cpu-py3\u0026#34; ROLE_ARN = \u0026#34;arn:aws:iam::064197589739:role/SageMakerExecutionRole\u0026#34; # Thay bằng Role ARN của bạn def lambda_handler(event, context): try: # 1. Lấy thông tin file vừa upload từ S3 Event s3_record = event[\u0026#39;Records\u0026#39;][0][\u0026#39;s3\u0026#39;] bucket = s3_record[\u0026#39;bucket\u0026#39;][\u0026#39;name\u0026#39;].strip() key = s3_record[\u0026#39;object\u0026#39;][\u0026#39;key\u0026#39;] model_url = f\u0026#34;s3://{bucket}/{key}\u0026#34; # Tạo tên unique cho model và endpoint dựa trên thời gian timestamp = time.strftime(\u0026#39;%Y-%m-%d-%H-%M-%S\u0026#39;, time.gmtime()) model_name = f\u0026#34;sklearn-model-{timestamp}\u0026#34; endpoint_config_name = f\u0026#34;endpoint-config-{timestamp}\u0026#34; endpoint_name = f\u0026#34;endpoint-serverless-{timestamp}\u0026#34; logger.info(f\u0026#34;Phát hiện model mới: {model_url}\u0026#34;) # 2. Tạo SageMaker Model # Lưu ý: Script inference.py của bạn PHẢI nằm trong model.tar.gz hoặc cấu hình biến môi trường để trỏ tới create_model_response = sm_client.create_model( ModelName=model_name, PrimaryContainer={ \u0026#39;Image\u0026#39;: CONTAINER_IMAGE_URI, \u0026#39;ModelDataUrl\u0026#39;: model_url, \u0026#39;Environment\u0026#39;: { \u0026#39;SAGEMAKER_PROGRAM\u0026#39;: \u0026#39;train.py\u0026#39;, # Tên file script chính của bạn \u0026#39;SAGEMAKER_SUBMIT_DIRECTORY\u0026#39;: model_url # Nơi chứa code (thường chung với model artifact) } }, ExecutionRoleArn=ROLE_ARN ) logger.info(f\u0026#34;Đã tạo Model: {model_name}\u0026#34;) # 3. Tạo Endpoint Configuration (SERVERLESS) create_config_response = sm_client.create_endpoint_config( EndpointConfigName=endpoint_config_name, ProductionVariants=[ { \u0026#39;VariantName\u0026#39;: \u0026#39;AllTraffic\u0026#39;, \u0026#39;ModelName\u0026#39;: model_name, \u0026#39;ServerlessConfig\u0026#39;: { \u0026#39;MemorySizeInMB\u0026#39;: 2048, # Chọn RAM: 1024, 2048, 3072... \u0026#39;MaxConcurrency\u0026#39;: 5 # Số request tối đa xử lý cùng lúc } } ] ) logger.info(f\u0026#34;Đã tạo Config Serverless: {endpoint_config_name}\u0026#34;) # 4. Tạo Endpoint create_endpoint_response = sm_client.create_endpoint( EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name ) return { \u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: f\u0026#34;Đang deploy Endpoint: {endpoint_name}. Quá trình này mất vài phút.\u0026#34; } except Exception as e: logger.error(f\u0026#34;Lỗi: {e}\u0026#34;) raise e Nhấn Deploy Sau khi Training \u0026amp; tunning tạo ra output là một model trong S3 thì sẽ tự động deploy model và tạo endpoint tương ứng Test endpoint Tạo 1 file input.json với data test bất kỳ [\u0026#34;testdata\u0026#34;, \u0026#34;test\u0026#34;] Test endpoint Thay endpoint-name bằng endpoint của bạn\naws sagemaker-runtime invoke-endpoint --endpoint-name endpoint-serverless-2026-01-09-06-04-49 --body fileb://input.json --content-type application/json output_file.json Kết quả trả về sẽ nằm trong file output_file.json có dạng tương tự:\n{ \u0026#34;status\u0026#34;: \u0026#34;success\u0026#34;, \u0026#34;prediction\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;Dummy Model\u0026#34;, \u0026#34;accuracy\u0026#34;: 99.9 }, \u0026#34;input_received\u0026#34;: [\u0026#34;testdata\u0026#34;, \u0026#34;test\u0026#34;] } "},{"uri":"https://kphuong08.github.io/Report/vi/5-workshop/5.3-training-flow/","title":"Xây dựng luồng Training tự động","tags":[],"description":"","content":"Xây dựng luồng Training tự động Trong phần này, chúng ta sẽ thiết lập cơ chế Event-Driven (hướng sự kiện). Mục tiêu là khi dữ liệu training mới được tải lên S3 Bucket, một Lambda Function sẽ tự động được kích hoạt. Lambda này đóng vai trò là \u0026ldquo;Orchestrator\u0026rdquo; để gọi API của SageMaker, bắt đầu một Training Job mới mà không cần sự can thiệp của con người.\nNội dung Tạo Lambda function Cấu hình S3 Event \u0026amp; kiểm thử "},{"uri":"https://kphuong08.github.io/Report/vi/4-eventparticipated/","title":"Các events đã tham gia","tags":[],"description":"","content":"Trong quá trình thực tập, em đã tham gia 2 events, với mỗi event là một trải nghiệm đáng nhớ với những kiến thức mới, hay và bổ ích, cùng với đó là nhứng món quà và những khoảnh khắc rất tuyệt vời.\nEvent 1 Tên sự kiện: Cloud Day VietNam 2025: Ho Chi Minh City Connect Edition for Builders\nThời gian: 09:00 ngày 18/09/2025\nĐịa điểm: Tầng 36, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 2 Tên sự kiện: Secure Your Applications: AWS Perimeter Protection Workshop\nThời gian: 09:00 ngày 19/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\n"},{"uri":"https://kphuong08.github.io/Report/vi/5-workshop/5.4-endpoint/","title":"Triển khai Serverless Endpoint","tags":[],"description":"","content":"Triển khai Serverless Endpoint Trong phần này, chúng ta sẽ đóng gói Model Artifact được tạo ra từ bước Training và triển khai nó lên SageMaker Serverless Inference. Khác với Real-time Endpoint (chạy máy chủ 24/7), Serverless Endpoint sẽ tự động co giãn về 0 khi không sử dụng, giúp tối ưu chi phí cho các ứng dụng có lưu lượng truy cập không thường xuyên.\nNội dung Tạo Model Cấu hình Serverless Endpoint Deploy và Invoke "},{"uri":"https://kphuong08.github.io/Report/vi/5-workshop/","title":"Workshop","tags":[],"description":"","content":"Tự động hóa quy trình MLOps trên AWS sử dụng SageMaker theo hướng Serverless Tổng quan Serverless MLOpsphương pháp tiếp cận hiện đại giúp giảm thiểu gánh nặng quản lý hạ tầng và tối ưu hóa chi phí bằng cách sử dụng các dịch vụ tự động co giãn của AWS.\nTrong workshop này, chúng ta sẽ thực hành xây dựng một quy trình khép kín: từ lúc dữ liệu thô được đưa lên Cloud cho đến khi Model sẵn sàng phục vụ người dùng, tất cả đều được kích hoạt tự động mà không cần duy trì bất kỳ máy chủ (server) nào chạy liên tục.\nChúng ta sẽ tập trung vào các thành phần Serverless chính sau đây:\nSageMaker Serverless Inference - Tính năng quan trọng nhất của bài lab. Cho phép triển khai Machine Learning Model dưới dạng API endpoint, tự động scale về 0 khi không có request. Bạn chỉ trả tiền cho thời gian tính toán thực tế. AWS Step Functions - Đóng vai trò bộ điều phối (Orchestrator). Thay thế cho các server Jenkins/GitLab Runner truyền thống để quản lý luồng training và deployment. Amazon EventBridge - Cơ chế kích hoạt theo sự kiện (Event-driven). Tự động phát hiện dữ liệu mới trên S3 để bắt đầu quy trình huấn luyện lại (Retrain) model. Nội dung Tổng quan về workshop Chuẩn bị Xây dựng luồng training tự động Triển khai Serverless Endpoint Dọn dẹp tài nguyên "},{"uri":"https://kphuong08.github.io/Report/vi/5-workshop/5.5-cleanup/","title":"Dọn dẹp tài nguyên","tags":[],"description":"","content":"Dọn dẹp tài nguyên Đây là bước quan trọng nhất để đảm bảo bạn không phát sinh chi phí AWS sau khi kết thúc Workshop. Chúng ta sẽ xóa các tài nguyên theo thứ tự ngược lại với quy trình tạo: Endpoint -\u0026gt; Model -\u0026gt; Data.\nXóa SageMaker Resources Thay tên endpoint của bạn vào đây\nXóa Endpoint aws sagemaker delete-endpoint --endpoint-name demo-serverless-endpoint # Hoặc tên endpoint tạo bằng CLI aws sagemaker delete-endpoint --endpoint-name demo-serverless-endpoint Xóa Endpoint Config aws sagemaker delete-endpoint-config --endpoint-config-name demo-serverless-config # Xóa cả config console nếu có aws sagemaker delete-endpoint-config --endpoint-config-name demo-serverless-config Xóa model # Lấy danh sách model để copy tên cho chính xác aws sagemaker list-models # Xóa model aws sagemaker delete-model --model-name demo-serverless-model Xóa Dữ liệu và Lambda Dọn sạch S3 Bucket # Thay tên bucket của bạn export BUCKET_NAME=\u0026#34;bucket của bạn\u0026#34; # Xóa toàn bộ objects (bao gồm code, data, model artifact) aws s3 rm s3://$BUCKET_NAME --recursive # Xóa bucket aws s3 rb s3://$BUCKET_NAME Xóa Lambda Function Vào Lambda console Chọn function cần xóa chọn Action -\u0026gt; Delete Xóa CloudWatch Log Groups Vào CloudWatch -\u0026gt; Logs -\u0026gt; Log Management Chọn các log cần xóa -\u0026gt; Action -\u0026gt; Delete log group(s) "},{"uri":"https://kphuong08.github.io/Report/vi/6-self-evaluation/","title":"Tự đánh giá","tags":[],"description":"","content":"Trong suốt thời gian thực tập tại Amazon Web Services Vietnam Co., Ltd, tôi đã có cơ hội học hỏi, rèn luyện và áp dụng kiến thức đã được trang bị tại trường vào môi trường làm việc thực tế.\nTôi đã tham gia Tự động hóa MLOps trên AWS theo hướng Serverless, qua đó cải thiện kỹ năng lập trình, viết báo cáo, sử dụng AWS.\nVề tác phong, tôi luôn cố gắng hoàn thành tốt nhiệm vụ, tuân thủ nội quy, và tích cực trao đổi với đồng nghiệp để nâng cao hiệu quả công việc.\nĐể phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ✅ ☐ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ✅ ☐ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ✅ ☐ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ✅ ☐ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ☐ ✅ ☐ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ☐ ✅ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ☐ ✅ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ☐ ✅ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ☐ ✅ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ✅ ☐ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ✅ ☐ ☐ Cần cải thiện Cải thiện trong việc sắp xếp công việc và sắp xếp thời gian một cách hợp lý Cải thiện khả năng giao tiếp tốt hơn trong giao tiếp hằng ngày và công việc, cũng như trong nhóm Cải thiện trong cách tư duy giải quyết vấn đề "},{"uri":"https://kphuong08.github.io/Report/vi/7-feedback/","title":"Chia sẻ, đóng góp ý kiến","tags":[],"description":"","content":"Đánh giá chung 1. Môi trường làm việc\nMôi trường làm việc rất thân thiện và cởi mở. Các thành viên trong FCJ rất năng động và luôn sẵn sàng hỗ trợ khi mình gặp khó khăn, kể cả ngoài giờ làm việc. Không gian làm việc gọn gàng, thoải mái, giúp mình tập trung tốt hơn. Tuy nhiên, mình nghĩ có thể bổ sung thêm một số buổi giao lưu trò chuyện, rủ nhau ăn trưa để có thể gần gũi nhau hơn.\n2. Sự hỗ trợ của mentor / team admin\nMentor sẳn sàng hỗ trợ, giải thích những gì mình chưa hiểu và luôn khuyến khích mình đặt câu hỏi. Team admin hỗ trợ các thủ tục, tài liệu và tạo điều kiện để mình làm việc thuận lợi.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nCông việc mình được giao phù hợp với kiến thức mình đã học ở trường, đồng thời mở rộng thêm những mảng mới mà mình chưa từng được tiếp cận. Nhờ vậy, mình vừa củng cố kiến thức nền tảng, vừa học thêm kỹ năng thực tế.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nTrong quá trình thực tập, mình học được nhiều kỹ năng mới như sử dụng công cụ quản lý dự án, kỹ năng làm việc nhóm, và cả cách giao tiếp chuyên nghiệp trong môi trường công ty. Mentor cũng chia sẻ nhiều kinh nghiệm thực tế giúp mình định hướng tốt hơn cho sự nghiệp.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nVăn hóa công ty rất tích cực: mọi người tôn trọng lẫn nhau, làm việc nghiêm túc nhưng vẫn vui vẻ. Khi có dự án gấp, mọi người cùng nhau cố gắng, hỗ trợ không phân biệt vị trí.\n6. Chính sách / phúc lợi cho thực tập sinh\nCông ty tạo điều kiện về thời gian linh hoạt khi cần thiết. Ngoài ra, việc được tham gia các buổi workshop, event giúp mình có thêm nhiều kiến thức hơn.\nMột số câu hỏi khác Điều bạn hài lòng nhất trong thời gian thực tập?\nMọi người rất thân thiện, sẵn sàng hỗ trợ bất cứ lúc nào. Đề xuất \u0026amp; mong muốn Bạn có muốn tiếp tục chương trình này trong tương lai? Có "},{"uri":"https://kphuong08.github.io/Report/vi/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://kphuong08.github.io/Report/vi/tags/","title":"Tags","tags":[],"description":"","content":""}]